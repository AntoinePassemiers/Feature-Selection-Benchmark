{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score    \n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "class CancelOut(keras.layers.Layer):\n",
    "    '''\n",
    "    CancelOut layer, keras implementation. \n",
    "    '''\n",
    "    def __init__(self, activation='sigmoid', cancelout_loss=True, lambda_1=0.002, lambda_2=0.001):\n",
    "        super(CancelOut, self).__init__()\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.cancelout_loss = cancelout_loss\n",
    "        \n",
    "        if activation == 'sigmoid': self.activation = tf.sigmoid\n",
    "        if activation == 'softmax': self.activation = tf.nn.softmax\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.keras.initializers.Constant(1),\n",
    "            trainable=True,\n",
    "        )\n",
    "    def call(self, inputs):\n",
    "        if self.cancelout_loss:\n",
    "            self.add_loss( self.lambda_1 * tf.norm(self.w, ord=1) + self.lambda_2 * tf.norm(self.w, ord=2))\n",
    "        return tf.math.multiply(inputs, self.activation(self.w))\n",
    "    \n",
    "    \n",
    "    def get_config(self):\n",
    "        return {\"activation\": self.activation}\n",
    "    \n",
    "\n",
    "    \n",
    "def define_model(p, co_activation,co_loss,s,n_layer):\n",
    "\n",
    "    inputs = keras.Input(shape=(p,))\n",
    "    x = CancelOut(activation=co_activation,cancelout_loss=co_loss)(inputs)\n",
    "    for i in range(n_layer):\n",
    "        x = layers.Dense(s)(x)\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    \n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(path,data_name,k_feat):\n",
    "    \n",
    "    data = np.genfromtxt(path+ data_name + str(k_feat) + 'feat.csv',delimiter=',')\n",
    "\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "def train_val_test_split(X,y,tr_idx,te_idx):\n",
    "    \n",
    "    # divide the data in train data (4/6), val data (1/6), test data (1/6)\n",
    "    \n",
    "    X_train, X_te = X[tr_idx], X[te_idx]\n",
    "    y_train, y_te = y[tr_idx], y[te_idx]\n",
    "    \n",
    "    st = te_idx[-1] + 1 - len(te_idx)\n",
    "    end = te_idx[-1]\n",
    "    if te_idx[-1] == 999:\n",
    "       \n",
    "        val_id = tr_idx[:len(te_idx)]\n",
    "        \n",
    "    else:\n",
    "       \n",
    "        val_id = tr_idx[st:end]\n",
    "    \n",
    "    X_val = X[val_id]\n",
    "    y_val = y[val_id]\n",
    "    no_train = np.concatenate((val_id,te_idx))\n",
    "    \n",
    "    X_tr = np.delete(X, no_train, 0)\n",
    "    y_tr = np.delete(y,no_train,0)\n",
    "    \n",
    "    return X_tr, X_val, X_te, y_tr, y_val, y_te\n",
    "\n",
    "def cv_training_CancelOut(X,y,n,model_name,siz,lr,n_layer):\n",
    "    \n",
    "    # n: number of folds for KFold cross-val\n",
    "    # model_name: identify the model when we save it. Last word must be \"sigmoid\" or \"softmax\", in this way we set cancelout layer\n",
    "    # siz: neurons of hidden layer(s)\n",
    "    # lr: learning rate\n",
    "    # n_layer: number of hidden layers\n",
    "    \n",
    "    if model_name[-7:] == 'sigmoid':\n",
    "        co_activation = 'sigmoid'\n",
    "        co_loss = True\n",
    "    if model_name[-7:] == 'softmax':\n",
    "        co_activation = 'softmax'\n",
    "        co_loss = False\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n)\n",
    "    \n",
    "    aucc = []\n",
    "    auprc = []\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for tr_idx, te_idx in kf.split(X):\n",
    "             \n",
    "        X_tr,X_val,X_te,y_tr,y_val,y_te = train_val_test_split(X,y,tr_idx,te_idx)\n",
    "        \n",
    "        model = define_model(X.shape[1],co_activation,co_loss,siz,n_layer)\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "       \n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt,metrics=['acc'])\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.33,patience=3, min_lr=0.00001)\n",
    "        history = model.fit(X_tr,y_tr, epochs=num_epochs,validation_data=(X_val,y_val), batch_size = 64,callbacks = [reduce_lr])\n",
    "        \n",
    "        \n",
    "        y_pred = model.predict(X_te)\n",
    "    \n",
    "        aucc.append(roc_auc_score(y_te,y_pred))\n",
    "        auprc.append(average_precision_score(y_te, y_pred))\n",
    "        print(\"lr\",lr,\" - size:\",siz)\n",
    "        print(\"Auc:\",aucc)\n",
    "        print(\"Auprc:\",auprc)\n",
    "        \n",
    "        dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "        outputDir = os.path.join( dataDir, 'CancelOut')\n",
    "        try:\n",
    "            os.stat(outputDir)\n",
    "        except:\n",
    "            os.mkdir(outputDir)\n",
    "\n",
    "        with open(os.path.join(outputDir, model_name + '_fold_'+ str(i) +'_importance.csv'), \"a+\") as myfile:\n",
    "            myfile.write(','.join([str(x) for x in model.get_weights()[0].flatten()]) + '\\n')\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    with open(os.path.join(outputDir, 'cv_cancelout_' + model_name + '_accuracy.csv'), \"a+\") as myfile:\n",
    "        myfile.write(str(accuracy))\n",
    "    with open(os.path.join(outputDir, 'cv_cancelout_' + model_name + '_cohen.csv'), \"a+\") as myfile:\n",
    "        myfile.write(str(cohen))\n",
    "    with open(os.path.join(outputDir, 'cv_cancelout_' + model_name + '_auc.csv'), \"a+\") as myfile:\n",
    "        myfile.write(str(aucc))\n",
    "    with open(os.path.join(outputDir, 'cv_cancelout_' + model_name + '_auprc.csv'), \"a+\") as myfile:\n",
    "        myfile.write(str(auprc))\n",
    "        \n",
    "        \n",
    "    return np.mean(aucc), np.mean(auprc) , np.var(aucc), np.var(auprc)     \n",
    "\n",
    "\n",
    "def get_features(model_names,n_split,k):                     \n",
    "    \n",
    "    # get the best k features from the model \"model_names\"\n",
    "    \n",
    "    best_feat = np.zeros((n_split,k))\n",
    "                     \n",
    "    \n",
    "    \n",
    "    for i in range(n_split):\n",
    "            \n",
    "        file = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features/'+ model_names[0] + '/' + model_names[1] + '_fold_'+ str(i) +'_importance.csv'\n",
    "        imp = np.genfromtxt(file,delimiter=',')[-1]\n",
    "        \n",
    "        print(imp.argsort()[-k:][::-1])    \n",
    "                \n",
    "        best_feat[i] = imp.argsort()[-k:][::-1]\n",
    "            \n",
    "                     \n",
    "    return best_feat\n",
    "\n",
    "def matches(best_feat,non_zero):\n",
    "    \n",
    "    # find how many features are important between the features selected by the model\n",
    "    \n",
    "    match = []\n",
    "    for i in range(len(best_feat)):\n",
    "        for j in range(len(non_zero)):\n",
    "            if best_feat[i] == non_zero[j]:\n",
    "                match.append(best_feat[i])\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING+XOR+SUM SOFTMAX\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring-xor-sum_1000samples-'\n",
    "h_size = 64\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [6,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring-xor-sum_'+str(i)+'_softmax',h_size,0.005,3)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 6\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_softmax'\n",
    "dataset = 'ring-xor-sum_'\n",
    "tot_feats = [6,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 6 or i == 8:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSoftmax_ring-xor-sum.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING+XOR+SUM SIGMOID\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring-xor-sum_1000samples-'\n",
    "h_size = 64\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [6,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring-xor-sum_'+str(i)+'_sigmoid',h_size,0.005,3)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 6\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_sigmoid'\n",
    "dataset = 'ring-xor-sum_'\n",
    "tot_feats = [6,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in [6,8,16,32,64,128,256,512]:\n",
    "    if i == 6 or i == 8:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSigmoid_ring-xor-sum.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING SOFTMAX\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring_1000samples-'\n",
    "h_size = 32\n",
    "num_epochs = 700\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [2,4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring_'+str(i)+'_softmax',h_size,0.005,1)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 2\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_softmax'\n",
    "dataset = 'ring_'\n",
    "tot_feats = [2,4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 2:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSoftmax_ring.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING SIGMOID\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring_1000samples-'\n",
    "h_size = 32\n",
    "num_epochs = 700\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [2,4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring_'+str(i)+'_sigmoid',h_size,0.005,1)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 2\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_sigmoid'\n",
    "dataset = 'ring_'\n",
    "tot_feats = [2,4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 2:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSigmoid_ring.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR SOFTMAX\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='xor_1000samples-'\n",
    "h_size = 16\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [2,4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'xor_'+str(i)+'_softmax',h_size,0.005,1)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 2\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_softmax'\n",
    "dataset = 'xor_'\n",
    "tot_feats = [2,4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 2:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSoftmax_XOR.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR SIGMOID\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-512 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='xor_1000samples-'\n",
    "h_size = 16\n",
    "num_epochs = 1000\n",
    "\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [2,4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'xor_'+str(i)+'_sigmoid',h_size,0.005,1)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 2\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_sigmoid'\n",
    "dataset = 'xor_'\n",
    "tot_feats = [2,4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 2:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSigmoid_XOR.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING XOR SOFTMAX\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-64 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring+xor_1000samples-'\n",
    "h_size = 64\n",
    "num_epochs = 2000\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring-xor_'+str(i)+'_softmax',h_size,0.005,3)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 4\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_softmax'\n",
    "dataset = 'ring-xor_'\n",
    "tot_feats = [4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 4:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSoftmax_RING-XOR.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RING XOR SIGMOID\n",
    "\n",
    "dataDir = '/Users/utente/Documents/università/tesi - confronto FS/analisi 2-64 features'\n",
    "\n",
    "path='./data/'\n",
    "data_name='ring+xor_1000samples-'\n",
    "h_size = 64\n",
    "num_epochs = 2000\n",
    "\n",
    "cv_auc = []\n",
    "var_auc = []\n",
    "cv_auprc = []\n",
    "var_auprc = []\n",
    "\n",
    "\n",
    "for i in [4,8,16,32,64,128,256,512]:\n",
    "    \n",
    "    X,y = set_data(path,data_name,i)\n",
    "\n",
    "    auccc,auprc,vauccc,vauprc = cv_training_CancelOut(X,y,6,'ring-xor_'+str(i)+'_sigmoid',h_size,0.005,3)\n",
    "\n",
    "    var_auc.append(vauccc)\n",
    "    cv_auc.append(auccc)\n",
    "    var_auprc.append(vauprc)\n",
    "    cv_auprc.append(auprc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 6\n",
    "K_feat = 4\n",
    "name0 = 'Cancelout'\n",
    "name1 = '_sigmoid'\n",
    "dataset = 'ring-xor_'\n",
    "tot_feats = [4,8,16,32,64,128,256,512]\n",
    "\n",
    "feat_res = []\n",
    "feat_res_2k = []\n",
    "\n",
    "# Best K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    feat_res.append(get_features([name0,dataset+str(i)+name1],splits,K_feat))\n",
    "    \n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        m[j,k] =len(matches(feat_res[j][k],np.arange(K_feat)))\n",
    "\n",
    "# best K feat averaged on the 6 folds\n",
    "cv_feat = np.mean(m,axis=1) \n",
    "var_feat = np.var(m,axis=1)\n",
    "\n",
    "# Best 2K features\n",
    "\n",
    "for i in tot_feats:\n",
    "    if i == 4:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(K_feat)))\n",
    "    else:\n",
    "        feat_res_2k.append(get_features([name0,dataset+str(i)+name1],splits,int(2*K_feat)))\n",
    "\n",
    "m = np.zeros((len(tot_feats),splits)) #rows=ring2,ring4,ring8... columns=fold0,fold1,fold2...\n",
    "for j in range(len(tot_feats)):\n",
    "    for k in range(splits):\n",
    "        \n",
    "        m[j,k] =len(matches(feat_res_2k[j][k],np.arange(int(K_feat))))\n",
    "        \n",
    "# best 2K feat averaged on the 6 folds\n",
    "cv_feat_2k = np.mean(m,axis=1)\n",
    "var_feat_2k = np.var(m,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "df = pd.DataFrame([cv_auc,var_auc,cv_auprc,var_auprc,cv_feat,var_feat,cv_feat_2k,var_feat_2k])\n",
    "df1 = df.T\n",
    "df1\n",
    "df1.to_excel(\"Auc-Auprc-KFeat-2KFeat_CanceloutSigmoid_RING-XOR.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
